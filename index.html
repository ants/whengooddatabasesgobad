<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>reveal.js – The HTML Presentation Framework</title>

		<meta name="description" content="A framework for easily creating beautiful presentations using HTML">
		<meta name="author" content="Hakim El Hattab">

		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/cybertec.css" id="theme">

		<!-- Code syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		
		<style type="text/css">
		.reveal h1 { font-size: 2.5em; color: #262842; }
		.reveal .level2 h1 { border-bottom: 0.05em solid #8393AE; }
		h1.title { border-bottom: 0.05em solid #8393AE; }
		.reveal blockquote { font-size: 0.75em; width: 85%; background-color: #e1eff4; padding: 0em 2em; border-bottom: 0.1em solid #8393AE; }
		</style>
		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
<section class="titleslide slide level1">
    <h1 style="font-size: 2em;" class="title">When good databases go bad</h1>
    <h2 style="font-size: 1em;">Dealing with database corruption</h2>
    <h3 style="font-size: 1em; margin-top: 3em;">Ants Aasma, Cybertec</h3>
</section>
<section>
    <section id="introductions" class="titleslide slide level1"><h1>Introductions</h1></section>
<section id="about-me" class="slide level2">
    <h1>About me</h1>
    <ul>
        <li>Currently I work for Cybertec, helping others run PostgreSQL.
        <ul>
            <li>High-availability setups</li>
            <li>Automated deployment</li>
            <li>Making PostgreSQL run <em>FAST</em>.</li>
            <li>Fix up databases that have gone pear shaped.</li>
        </ul></li>
        <li>Previously a software architect at Estonian Ministry of Interior.</li>
        <li>ants@cybertec.at</li>
    </ul>
    <aside class="notes"><p>Boring stuff like document management systems or passport records keeping or realtime tracking and routing of firetrucks.</p></aside>
</section>
<section id="introduction" class="slide level2">
    <h1>The problem statement</h1>
    <ul>
        <li>PostgreSQL is a very reliable piece of software</li>
        <li>But sometimes Bad Stuff just happens</li>
        <li>Being prepared will make the difference.</li>
    </ul>
    <blockquote>
    <code>ERROR:  invalid page in block 572319 of relation base/123456/234567</code>
    </blockquote>
    <blockquote>
    <code>ERROR:  invalid memory alloc request size 18446744073709551614</code>
    </blockquote>
    <aside class="notes"><p>I will try to answer questions as we go, but if I'm running short on time I will let you know and if we have time left at the end we can answer then.</p></aside>
</section>
<section id="overview-of-the-talk" class="slide level2">
    <h1>Overview of the talk</h1>
    <ul>
        <li>What can go wrong</li>
        <li>What to do when corruption does happen</li>
        <li>How to recover</li>
        <li>Keeping out of trouble</li>
    </ul>
<aside class="notes"><p>Because you can't fix it if you don't know what is broken.</p></aside>
    
</section>
</section>

<section><section id="what-can-go-wrong" class="titleslide slide level1"><h1>What can go wrong?</h1>
<aside class="notes"><p>5 min mark</p></aside></section><section id="hardware-failures" class="slide level2">
<h1>Hardware failures</h1>
<ul>
<li>Broken hardware means broken databases.</li>
<li>Lots of stuff can break your server, but for data integrity we can make do with a simplified view.
<ul class="fragment">
<li>CPU</li>
<li>RAM</li>
<li>Network</li>
<li>Storage</li>
<li>Power supply</li>
</ul></li>
</ul>
</section><section id="cpu" class="slide level2">
<h1>CPU</h1>
<ul>
<li>Rarely the issue</li>
<li>Mostly causes crashes when it is</li>
</ul>
</section><section id="ram" class="slide level2">
<h1>RAM</h1>
<ul>
<li>Failures are rather frequent.</li>
<li>Occasional 1 bit errors (&quot;cosmic rays&quot;) are more rare than broken chips (e.g. row line stuck at 1).</li>
<li>Can silently corrupt large amounts of data.</li>
<li>ECC mostly fixes it.</li>
</ul>
<aside class="notes"><p>ECC means crashes, instead of corrupted data.</p></aside>
</section><section id="network" class="slide level2">
<h1>Network</h1>
<ul>
<li>TCP/IP checksums by and large take care of the data integrity issues.</li>
<li>Use SSL if you need protection from nefarious agents or for a belt-and-suspenders approach.</li>
<li>More about availability than integrity.</li>
</ul>
<aside class="notes"><p>When in doubt, test.</p></aside>
</section><section id="storage" class="slide level2">
<h1>Storage</h1>
<ul>
<li>Modern drives are on the edge of not working.
<ul>
<li>Raw media error rate is about 1:1000.</li>
<li>Average block read has 32 errors.</li>
</ul></li>
<li>SSDs are not any better.</li>
<li>Error correction codes mostly fix it under the covers by using 100 bytes of ECC per 4k block.
<ul>
<li class="fragment">Except when they don't.</li>
</ul></li>
</ul>
<aside class="notes"><p>SSDs forget data and need to be refhreshed. Don't use them store your backups.</p></aside>
</section><section id="bad-blocks" class="slide level2">
<h1>Bad blocks</h1>
<p></p>
<ul>
<li>Outside of specialized data recovery shops that data is gone.</li>
<li>Get your database off that drive <strong>ASAP</strong>, before further damage occurs!</li>
</ul>
<aside class="notes"><p>Shows up in kernel logs as IO error. Good part is that you will notice it.</p></aside>
</section><section id="silent-data-corruption" class="slide level2">
<h1>Silent data corruption</h1>
<blockquote>
<p>&quot;Of the total sample of 1.53 million disks, 3855 disks developed checksum mismatches – 3088 of the 358,000 nearline disks (0.86%) and 767 of the 1.17 million enterprise class disks (0.065%).&quot; - <a href="https://www.usenix.org/legacy/event/fast08/tech/full_papers/bairavasundaram/bairavasundaram.pdf">An Analysis of Data Corruption in the Storage Stack</a></p>
</blockquote>
<ul>
<li>Misdirected writes.</li>
<li>Writes replaced with zeroes.</li>
<li>Torn writes.</li>
<li>Bit errors and garbage data is pretty rare.</li>
<li>If there is damage it's pretty likely to have large amounts of it.</li>
</ul>
</section><section id="power-supply" class="slide level2">
<h1>Power supply</h1>
<ul>
<li>In theory losing power will not cause data loss.</li>
<li>In practice...
<ul>
<li>Some drives, especially cheap SSDs, lie about <code>fsync</code><ul><li>If <code>pg_test_fsync</code> numbers are too good to be true, the probably are.</li></ul></li>
<li>PostgreSQL crash recovery does not get as much testing as normal operation.</li>
<li>Spectacular power supply failures can fry your whole RAID set at once.</li>
</ul></li>
</ul>
</section><section id="software-failures" class="slide level2">
<h1>Software failures</h1>
<ul>
<li>Filesystem, storage driver, hypervisor, etc.</li>
<li>PostgreSQL</li>
<li>Backup and replication tools</li>
<li>Firmware and other magic hidden in your storage system</li>
</ul>
</section><section id="operator-failures" class="slide level2">
<h1>Operator failures</h1>
<ul>
<li>Incorrect (or missing) backup practices</li>
<li>Accidental <code>DROP TABLE</code></li>
<li>Overzealous optimization
<ul>
<li>Do <strong>NOT</strong> touch <code>fsync</code> and <code>full_page_writes</code></li>
</ul></li>
<li>Multiple servers accessing a single data dir.</li>
<li>&quot;Why are all these logs are taking up disk space? They're not even readable.&quot;</li>
</ul>
</section></section>
<section><section id="what-to-do-when-stuff-has-hit-the-fan" class="titleslide slide level1"><h1>What to do when stuff has hit the fan?</h1></section><section id="keep-calm" class="slide level2">
<h1>Keep calm</h1>
<ul>
<li>It's easy to cause more issues by making rash decisions.</li>
<li>Try not to burn any bridges.</li>
</ul>
</section><section id="keep-notes" class="slide level2">
<h1>Keep notes</h1>
<ul>
<li>During times of stress it's easy to forget stuff and overlook things.</li>
<li>Write down all error messages, steps you have tried, etc.</li>
<li>It's extremely helpful when you need to get external help.</li>
</ul>
</section><section id="first-do-no-harm" class="slide level2">
<h1>First, do no harm</h1>
<ul>
<li>Take a physical backup before you make things worse by trying to fix them.<ul>
<li>Preferrably an offline backup.</li>
<li>If offline backup is not possible, check to see if the backup is actually usable before continuing.</li>
</ul></li>
<li>Arrange for WALs to be kept around.</li>
<li>Turn off any automated failover software.</li>
<li>In case you do screw up, you can try again.</li>
<li>In most cases disable application access while you are working.</li>
</ul>
</section><section id="find-and-fix-the-root-cause" class="slide level2">
<h1>Find and fix the root cause</h1>
<ul>
<li>Every case of corruption is different.</li>
<li>Figure out what is causing the problem and try to eliminate it.</li>
<li>Establish that things are sane from the bottom up.
<ul>
<li>Is the hardware running ok?</li>
<li>Any interesting error messages in system logs?</li>
<li><p>Is the data readable?</p>
<pre><code>find $PGDATA -type f | xargs -l md5sum</code></pre></li>
<li>Any recent crashes?</li>
</ul></li>
</ul>
<aside class="notes"><p>Crashes cause corruption and corruption causes crashes.</p></aside>

</section><section id="establish-a-plan" class="slide level2">
<h1>Establish a plan</h1>
<ul>
<li>You need to figure out what steps to take to get back to a correctly running database.</li>
<li>What is the last usable backup?</li>
<li>Do you have WAL to do PITR from that point?</li>
<li>Is it more important to get the database up or retain all data.</li>
<li>Is it something you can fix in an automated fashion or do you need manual fixups.</li>
</ul>
<aside class="notes"><p>Restoring a backup will create a fork in the timeline. Merging the two branches is usually tricky manual labor.</p></aside>

</section></section>
<section><section id="how-to-recover" class="titleslide slide level1"><h1>How to recover</h1><aside class="notes"><p>Tips for some common classes of corruption.</p></aside></section><section id="index-corruption" class="slide level2">
<h1>Index corruption</h1>
<ul>
<li>Complex data structure with tricky locking, so most likely to have bugs.</li>
<li>Errors will manifest as strange query output, infinite loops.
<ul><li>Broken indexes on system catalog indexes can result in very strange errors.</li></ul>
</li>

<li>Can be fixed by rebuilding the index using <code>REINDEX</code>.
<ul>
<li>For unique indexes you may get constraint violations. These will need manual fixing.</li>
</ul></li>
<li>Ensure you are using the latest version and your hardware is working correctly.
<ul>
<li>If everything else is working correctly, report a bug.</li>
</ul></li>
</ul>
<!-- add symptoms here -->
</section><section id="table-corruption" class="slide level2">
<h1>Table corruption</h1>
<ul>
<li>Most likely you will lose data.</li>
<li>Can take many forms, depending on where the bogus data is.
<ul>
<li>Garbage in page header usually results in whole page becoming unreadable.</li>
<li>Garbage in tuple header (bogus xmin/xmax) causes clog/multixact misses.</li>
<li>Garbage in row itself can be silently returned, result in memory allocation failures or even crashes.</li>
<li>Badly linked row versions are also possible.</li>
</ul></li>
<li>Dump and restore is the best bet.</li>
</ul>
</section><section id="pg_dump-failure" class="slide level2">
<h1>Handling pg_dump failure</h1>
<ul>
<li>If dump fails with errors, bisect around the broken data.</li>
<li>I have a little tool that extracts everything readable:<blockquote><a href="https://github.com/ants/pg-recovery-tools/blob/master/trycopy.py" class="uri">https://github.com/ants/pg-recovery-tools/blob/master/trycopy.py</a></blockquote></li>
<li>Tries to copy out a table in recursively smaller batches until it identifies the page and line pointer numbers that is causing errors or crashes. Logs them for detailed study.<ul><li>pageinspect can provide some useful information</li><li>Taking a quick look with a hex editor may also be useful</li></ul></li>
<li>CTID scans for PostgreSQL would make this tool a lot faster...</li>
</ul>
</section><section id="clog-corruption" class="slide level2">
<h1>Clog corruption</h1>
<ul>
<li>Invalid data leads to duplicate rows/missing rows.</li>
<li>Missing CLOG pages means you can't access rows that reference them.
<ul>
<li>More likely to be caused by heap corruption and bogus XIDs.</li>
<li>To rescue data you can fake the file by filling it with 0x55 (everything commited). Expect manual cleanup of extracted data.</li>
</ul></li>
</ul>
</section><section id="pg_resetxlog" class="slide level2">
<h1>pg_resetxlog</h1>
<ul>
<li>pg_resetxlog <strong>WILL</strong> break your database.</li>
<li>Use it when database does not come up and you want extract at least some data.</li>
<li>dump/restore is required after using.</li>
<li>I have a little tool that allows you to replace error causing records with empty ones.</li>
</ul>
<blockquote><a href="https://github.com/ants/pg-recovery-tools/blob/master/xlogfilter.py" class="uri">https://github.com/ants/pg-recovery-tools/blob/master/xlogfilter.py</a></blockquote>
</section></section>
<section><section id="how-to-keep-yourself-out-of-trouble" class="titleslide slide level1"><h1>How to keep yourself out of trouble?</h1></section><section id="keep-up-to-date-on-updates" class="slide level2">
<h1>Keep up to date on updates</h1>
<ul>
<li>New versions fix bugs.
<ul>
<li>You are more likely to have an issue due to not installing a bugfix release than installing it.</li>
</ul></li>
<li>Recently had a client with corruption on a PostgreSQL 7.4.1 instance.</li>
<li>Upgrade your kernel too.</li>
</ul>
</section><section id="backups" class="slide level2">
<h1>Backups</h1>
<ul>
<li>Take regularly scheduled backups.</li>
<li>Keep as many as you can afford. Have a retention schedule.
<ul>
<li><code>x</code> daily backups, <code>y</code> weekly backups, <code>z</code> monthly backups</li>
</ul></li>
<li>Test restoring from a backup.</li>
<li>Use WAL archiving for PITR capability.<ul><li>pg_receivexlog is very useful</li></ul></li>
</ul>
</section><section id="dont-use-flaky-hardware" class="slide level2">
<h1>Don't use flaky hardware</h1>
<ul>
<li><p>Not using ECC memory is just asking for trouble.</p>
<blockquote>
<p>&quot;For example, we observe DRAM error rates that are orders of magnitude higher than previously reported, with 25,000 to 70,000 errors per billion device hours per Mbit and more than <strong>8% of DIMMs affected by errors per year</strong>.&quot; - <a href="https://www.cs.toronto.edu/~bianca/papers/sigmetrics09.pdf">DRAM Errors in the Wild: A Large-Scale Field Study</a></p>
</blockquote></li>
<li>Consumer level storage devices play fast and loose with your data.</li>
<li><p>Overclocking your database server is a bad idea.</p></li>
</ul>
</section><section id="checksums" class="slide level2">
<h1>Checksums</h1>
<ul>
<li>WAL is checksummed by default.</li>
<li>You can turn on data checksums at initdb time.
<ul>
<li>Provides early detection, <em>if</em> you do regular scrubbing.</li>
</ul></li>
<li>Clog has no checksums :(</li>
<li>BTRFS or ZFS will also give you checksums.
<ul>
<li>Huge throughput hit (50%), even on SSDs.</li>
<li>BTRFS has horrible behaviors under heavy write loads.</li>
<li>If your workload is light the nice features may still be worth it.</li>
</ul></li>
</ul>
</section><section id="redundancy" class="slide level2">
<h1>Redundancy</h1>
<ul>
<li>RAID1 and RAID5 can save you from the occasional bad block or failed drive.</li>
<li class="fragment">Having a streaming replica will handle storage failures <strong>AND</strong> can also save your skin from OS level failures.
<ul>
<li class="fragment">Redundant Array of Inexpensive Servers</li>
</ul></li>
<li class="fragment">PostgreSQL bugs are likely to cause corruption that gets replicated to standbys.</li>
</ul>
</section><section id="logical-backups" class="slide level2">
<h1>Logical backups</h1>
<ul>
<li>Run logical backups on a regular schedule.</li>
<li>If you can't afford the throughput hit and long snapshot on the master server use a hot standby.
<ul>
<li>hot_standby_feedback = off</li>
<li>max_standby_streaming/archive_delay = -1</li>
<li>You probably don't want to use a high-availability standby for this</li>
</ul></li>
<li>Logical backups make sure that everything in the database is still readable.</li>
</ul>
</section></section>
<section><section id="overview" class="titleslide slide level1"><h1>Putting it all together</h1></section><section id="recipe-for-retaining-your-data" class="slide level2">
<h1>Recipe for retaining your data</h1>
<ul>
<li>Have backups available.</li>
<li>Keep on top of bug fixes.</li>
<li>Scrub your data.</li>
<li>When things go south, keep calm, keep notes and </li>
</ul>
<!--
Filesystem 

Dealing with database corruption



More bits & same size => smaller bits
Smaller bits => Increased per bit error

More bits && More errors per bit => Bad stuff


Literature:

DRAM errors in the wild
https://www.cs.toronto.edu/~bianca/papers/sigmetrics09.pdf

"For example, we observe DRAM error rates that are orders of magnitude higher than previously reported, with 25,000 to 70,000 errors per billion device hours per Mbit and more than 8% of DIMMs affectedby errors per year."

Are Disks the Dominant Contributor for Storage Failures? 
https://www.usenix.org/legacy/event/fast08/tech/full_papers/jiang/jiang_html/


Data corruption kinds

Data path corruption
Misdirected write
Torn write
Missed wrte

RAID-5 
Scrubbing



Logical backups help detect problems



https://www.usenix.org/legacy/event/fast08/tech/full_papers/bairavasundaram/bairavasundaram.pdf

"Of the total sample of 1.53 million disks, 3855 disks developed checksum mismatches –  3088 of the 358,000 nearline disks (0.86%) and 767 of the 1.17 million enterprise class disks (0.065%)."


Table corruption
Index corruption
Toast corruption
Clog corruption, xlog corruption



-->
</section></section>
<section><section id="that-is-all" class="titleslide slide level1"><h1>That is all</h1></section></section>
<section><section id="questions" class="titleslide slide level1"><h1>Questions?</h1></section></section>
			</div>
<div id="cybertecLogo" style="background: url(images/logo.png); position: absolute; bottom: 2.5%; left: 3%; width: 14%; height: 0; padding-bottom: 7%; background-size: 100% 100%;"></div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// Full list of configuration options available at:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,
				transition: 'slide', // none/fade/slide/convex/concave/zoom
				transitionSpeed: 'fast',
				// Optional reveal.js plugins
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true }
				]
			});
		</script>

	</body>
</html>
